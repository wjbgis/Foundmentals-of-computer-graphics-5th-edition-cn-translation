# 4. 光线追踪



计算机图形学的基本任务之一是绘制三维对象：在一个有许多三维几何物体的场景中，计算出从特定视点查看场景时对应的二维图像。这相当于几个世纪以来的建筑师和工程师将他们设计的图纸展示给其他人。

从根本上说，渲染是一个输入一组物体（objects）并输出一组像素的过程。总而言之，渲染需要考虑每个物体对每个像素产生的作用，它可以分为两种。一种是**对象顺序渲染**（object-order rendering），依次考虑每个对象，找到并更新该物体影响的所有像素。另一种是**图像顺序渲染**（image-order rendering），依次考虑每个像素，对每一像素都查找影响其取值的物体并最终计算像素值。可以从循环嵌套的角度来描述两者的区别：在基于图像顺序渲染中，“for each pixel” 循环在外部，而在基于对象顺序渲染中，“for each object”循环在外部。

”图像顺序“和”对象顺序“渲染器可以精确地计算出相同的图像，但它们可以用于计算不同类型的效果，并具有截然不同的性能特征，本书将在第9章中讨论两种方式的优缺点。但一般来说，图像顺序渲染更容易达到效果并且更加灵活，但通常也需要更长的时间来产生相应的图像。

**光线追踪**（ray tracing）是一种3D场景中基于图像顺序渲染的算法。我们将首先研究光线追踪的机制，因为在不了解任何应用于对象顺序渲染的数学机制的情况下，也能编写一个有效的光线追踪器（ray tracer）。



## 4.1 光线追踪基础算法



光线追踪器的原理是：一次计算一个像素，对于每个像素，基本任务是找到图像中该像素位置可以看到的物体。每个像素“看”向不同的方向，像素看到的任何对象都必须与观测射线（*viewing ray*）相交，观测射线是一条从视点发出发并指向被观测像素的线。我们想要的一个特定物体是与观测射线相交并距离相机最近的物体，因为该物体挡住了后面所有物体的视线。一旦找到该物体，我们就会使用交点，表面法线和其它信息（取决于所需的渲染类型）来进行着色计算，并最终得出像素点的颜色。上述原理如图4.1所示，观测射线和两个物体T1，T2两个对象相交，但我们只对T2进行着色。

<img src="4. 光线追踪.assets/image-20220911180707102.png" alt="image-20220911180707102" style="zoom: 33%;" />

<center>图4.2 光线”追踪“到场景中，第一个命中的对象就是像素看到的对象，这种情况下返回三角形T2</center>

一个基础的光线追踪器由3部分组成：

1. **光线生成**（ray generation），根据相机几何计算每个像素观测射线的起点和方向。
2. **光线相交**（ray intersection），找到最近的与观测射线相交的物体。
3. **着色**（shading），根据光线相交的结果计算像素颜色。

光线追踪的基本代码结构如下：

```tex
for each pixel do
	compute viewing ray
	find first object hit by ray and its surface normal n
	set pixel color to value computed from hit point, light, and n
```

本章内容涵盖了光线生成、光线相交和着色的基本方法，这些方法足以让我们实现一个简单的光线跟踪器demo。但如果开发一个真正有用的系统，还需要涉及到第12章中更有效的光线相交技术，光线追踪器的真正潜力将通过第10章中更高级的着色方法和第13章中额外的渲染技术体现出来。



## 4.2 透视



在计算机出现前的几百年里，艺术家们就已经研究了用2D绘画或颜料来表现3D物体或场景的问题，我们常见的照片也可以用2D图像表示3D场景。虽然有许多非传统的方法来制作图像，从立体主义绘画到鱼眼镜头（图4.2）到外围相机，但艺术和摄影以及计算机图形学的标准方法都是*线性透视*（*linear perspective*），在这种方法中，3D对象被投影到*像平面*（*image plane*）上，这样场景中的直线就变成了图像中的直线。

<img src="4. 光线追踪.assets/image-20220912100545839.png" alt="image-20220912100545839" style="zoom: 50%;" />

<center>图4.2 用鱼眼镜头拍摄的图像不是线性透视图像</center>

最简单的投影类型是*平行投影*（*parallel projection*），即3D点沿着投影方向移动到2D平面，直到它们到达图像平面（图4.3-4.4）。平行投影所产生的视图是由*投影方向*（*projection direction*）和像平面决定的。如果像平面垂直于观测方向，则称为*正射投影*（*orthographic*）;否则称为*斜轴投影*（*oblique*）。

<img src="4. 光线追踪.assets/image-20220912101713641.png" alt="image-20220912101713641" style="zoom: 33%;" />

<center>图4.3 当投影线互相平行且垂直于像平面时，得到的视图称为正射视图。</center>

<img src="4. 光线追踪.assets/image-20220912102122264.png" alt="image-20220912102122264" style="zoom: 33%;" />

<center>图4.4 像平面与投影方向成一定角度的平行投影称为斜轴投影(右)。在透视投影中，投影线都穿过视点，而不是互相平行的(左)。图中透视图是非斜轴投影，因为通过图像中心绘制的投影线垂直于图像平面。</center>

平行投影常用于机械和建筑制图，因为它能使平行线保持平行，并能保持平行于像平面的平面物体的大小和形状。但平行投影的优点即缺点，在我们的日常经验中，近大远小（在照片中更是如此），因此向远处延伸的平行线视觉上看起来是不平行的。这是因为眼睛和相机不能从单一的观察方向收集光线，它们收集的是穿过特定视点的光。自文艺复兴以来，艺术家们就已经认识到，我们可以使用*透视投影*（*perspective projection*）绘制自然景观：沿着穿过一个点(视点)的一组线束进行投影，来替代平行的线束（图4.4），这样，距离视点较远的物体在投影时自然就变得很小。透视投影所产生的视图是由视点（而不是投影方向）和像平面决定的。与平行视图一样，根据图像中心的投影方向，透视视图也有有斜轴视图和非斜轴视图之分。

您可能对艺术中的*三点透视*（*three-point perspective*）有所了解，这是一种手动构建透视图的方式(图4.5)。关于透视的一个令人惊讶的事实是，如果我们遵循透视背后的简单数学规则，所有的透视绘制规则都会自动遵循：物体直接朝向眼睛投影，它们被绘制在眼睛前面的视图平面上。

<img src="4. 光线追踪.assets/image-20220912110154889.png" alt="image-20220912110154889" style="zoom:50%;" />

<center>图4.5 在三点透视法中，艺术家选择平行线相交的点作为“消失点”（vanishing point）。平行线相交于水平线上的一点。每一组平行线都有自己的消失点。</center>



## 4.3 计算观测射线（viewing rays）



在上一节中，光线生成的基本要素是视点（或者平行视图的投影方向）和像平面。有许多方法来解决相机几何细节问题，在本节中，我们将介绍一个基于标准正交基的方法，它可以用于正轴和斜轴平行视图，以及正射视图。

为了生成光线，我们需要首先了解光线的数学描述。在数学上，一条光线实际上只有**一个原点和一个传播方向**，一个3D空间的直线很适用于描述光线。如2.5.7节所述，人眼 **e** 到图像平面上 **s** 点的三维参数化直线（图4.6）可以表示为：
$$
\pmb{p}(t)=\pmb{e}+t(\pmb{s}-\pmb{e})
$$
<img src="4. 光线追踪.assets/image-20220912115508122.png" alt="image-20220912115508122" style="zoom:50%;" />

<center>图4.6 从眼睛到像平面上一点的光线</center>

上述公式可以这样理解：我们从**e**沿着向量(**s**−**e**)行进一段距离t，以找到点p。给定t，我们可以确定一个点**p**，点**e**是射线的原点，**s** - **e**是射线的方向。

可以注意到**p**(0) = **e**，**p**(1) = **s**；如果0 < t1 < t2，那么**p**(t1)比**p**(t2)更靠近我们的眼睛；如果t < 0，那么**p**(t)在我们的眼睛”后面“。当我们寻找光线照射到的离眼睛最近的物体时，就会用到这些特性。

在代码中，可以使用包含起点和方向的结构或对象来表示光线。例如在面向对象程序中，我们可以这样写：

```c++
class Ray
	Vec3 o | ray origin
	Vec3 d | ray direction
	Vec3 evaluate(real t) 
       return o + td
```

我们假设*Vec3*是一个表示三维向量的类，并且支持常规的算数运算。

为了计算观测射线，我们需要知道**e**(已经给出)和**s**。找到**s**似乎很难，但如果我们在坐标中解决这个问题，实际上是很简单的 。

所有的射线都基于一个正交直角坐标系，即相机坐标系（*camera frame*）。如图4.7所示，我们用**e**表示视点（眼睛所在位置），用 **u**、**v**和 **w** 表示三个基向量，其中**u**指向右方(相机所看的方向为正前方)，**v**指向上方，**w**指向后方，这样 {**u, v, w**} 就形成了一个右手坐标系。构造相机坐标系的常用方法是以**e**为视点，相机的观测方向为-**w**，上方是**v**；基于过**w**和**v**，使用2.4.7所描述的由两个向量构建正交基的方法，进而得到**u**（图4.8）。



<img src="4. 光线追踪.assets/image-20220912121700718.png" alt="image-20220912121700718" style="zoom:50%;" />

<center>图4.7 屏幕上的示例点被映射到3D窗口的阵列数组。观测射线指向窗口中的每一个点。</center>

<img src="4. 光线追踪.assets/image-20220912124627949.png" alt="image-20220912124627949" style="zoom:67%;" />

<center>图4.8 相机坐标系，向量w和观测方向相反，向量v和相机正上方共面。</center>



### 4.3.1 正射视图

对于正射视图，所有的光线方向均为-**w**。尽管平行视图没有正射视图那样的视点，我们仍然可以使用相机坐标系的原点来定义光线的起始平面。

观察射线的起点应该在点**e**和向量**u**和**v**所定义的平面，接下来只需要知道的信息是图像应该在平面的什么位置。我们用四个数字来定义图像尺寸，即图像的四条边：l 和 r 是图像的左右边界，是从**e**沿**u**方向测量得到的；t 和 b 是图像的上下边界，是从**e**沿着**v**方向测量得到的。通常 l < 0 < r，b < 0 < t，详见图4.9。

<img src="4. 光线追踪.assets/image-20220912144111333.png" alt="image-20220912144111333" style="zoom:50%;" />

<center>图4.9 使用相机框架生成光线。左：在正射视图中，光线从图像平面上的像素位置开始，且所有光线方向都相同，即视图方向。右图：在透视图中，光线从视点开始，每条光线的方向由视点 e 和像素在图像平面上的位置定义。</center>

在第3.2节中，我们提到了图像中的像素坐标。为了把有$n_x×n_y $像素的图像放入大小为$(r−l) × (t−b)$的矩形中，则水平方向像素点的间隔应为$(r−l)/nx$，竖直方向像素点的间隔应为$(t−b)/ny$，且像素矩形边缘到像素点的距离为半个像素的宽度。 这意味着实际栅格图像中位置为$(i, j)$的像素在图像平面中的位置为：
$$
u = l + (r − l)(i + 0.5)/n_x,\\
v = b + (t − b)(j + 0.5)/n_y\tag{4.1}
$$
其中$(u, v)$是像素在图像平面上的位置坐标，是相对于原点**e**和基准{**u**, **v**}测得的。

在正射视图中，我们可以简单地使用像素的图像平面位置作为射线的起点，并且我们已经知道射线的方向就是视图的方向。生成正射视图观测射线的程序如下：

​	使用公式4.1计算$u$和$v$

​	ray.o ← **e** + $u$ **u** +$v$ **v**

​	ray.d ← −**w**

生成斜轴平行视图非常简单：只需要将图像平面的法线方向**w**和观测方向**d**区别开, 使用**d**替代-**w** 。当然，我们依然使用法线方向**w**来构建**u**和**v**。



### 4.3.2 透视视图

对于透视图，所有射线都有同一个原点——视点，射线指向每个像素的方向是不同的。图像平面也不再位于**e**所在的平面，而是在**e**前方一定距离 d 处，这个距离 d 是图象平面的距离，通常被广义的称作焦距（*focal length*），这是因为 d 的设定和现实中相机的焦距的设定是一样的。每条射线的方向都是由视点位置和像素在图像平面上的位置决定的，这种情况如图4.9所示。生成透视视图的观测射线的程序和正射视图类似：

​	使用公式4.1计算$u$和$v$

​	ray.o ← **e** 

​	ray.d ← −$d$**w** + $u$**u** + $v$**v**

与平行投影视图一样，斜轴透视视图可以通过区分平面法线方向和观测方向来实现。



## 4.4 光线-物体求交



